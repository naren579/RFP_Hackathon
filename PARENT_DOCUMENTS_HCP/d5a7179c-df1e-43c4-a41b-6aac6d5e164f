800/907

6/25/24, 11:34 AM

Content Platform System Management Help

import os mTime = os.path.getmtime("/datamount/images/wind.jpg") aTime = 1431878400 #12:00 May 17th 2015 os.utime("/datamount/images/wind.jpg", (aTime, mTime))

Example: Creating a symbolic link

This example creates a symbolic link named big_dipper that references an object named ursa_major.jpg.

Unix command

ln -s /datamount/images/constellations/ursa_major.jpg /datamount/constellations/common_names/big_dipper Python code

import os

os.symlink("/datamount/images/constellations/ursa_major.jpg", "/datamount/constellations/common_names/big_dipper"

Example Retrieving an object

This example retrieves the object named wind.jpg from a namespace and stores the resulting file in the retrieved_files directory.

Unix command cp /datamount/images/wind.jpg retrieved_files/wind.jpg

Python code

import shutil shutil.copy("/datamount/images/wind.jpg", "retrieved_files/ \

wind.jpg")

NFS usage considerations

This chapter presents considerations that affect the use of the NFS protocol for namespace access.

Note: HCP is an object store with multiple gateways that support various protocols. The NFS protocol exists on HCP to support legacy applications that do not have modern HTTP

REST/S3 support. The NFS protocol on HCP is not designed to support direct end-user access.

NFS lazy close

When writing a file to the namespace, NFS can cause a flush at any time and never issue a close. After each flush or write, HCP waits a short amount of time for the next one. If no

write occurs within that time, HCP considers the resulting object to be complete and automatically closes it. This event is called lazy close. If you set retention on an object during the lazy close period, HCP closes the object immediately. The object becomes WORM, and retention applies, even if the object contains no data. However, if the directory that contains the object and its corresponding metadirectory are mounted on two different nodes in the HCP system, setting retention during the lazy

close period does not close the object.

Using NFS with objects open for write

These considerations apply to objects that are open for write through any protocol:

While an object is open for write through one IP address, you cannot open it for write through any other IP address. You can read an object that is open for write from any IP address, even though the object data may be incomplete. A read against the node hosting the write may return more

data than a read against any other node. While an object is open for write, you cannot delete it. Note: Depending on the timing, the delete request may result in a busy error. In that case, wait one or two seconds and then try the request again. While an object that’s open for write has no data:

It is not WORM It may or may not have a cryptographic hash value

It is not subject to retention It cannot have custom metadata

It is not indexed It is not replicated

Note: If you observe multiple stale NFS file handle errors on an NFS client, you might resolve the issue by disabling client-side caching. To do this, add the mount option lookupcac he=none to the command. The complete set of options will be:

o tcp,vers=3,timeo=600,hard,intr,lookupcache=none

Setting this option will enhance the consistency of client access and may assist in mitigating the issue. However, it's important to note that it may also result in a significant degradation of performance.

Failed NFS write operations An NFS write operation is considered to have failed if the target node failed while the object was open for write. Also, in some circumstances, a write operation is considered to have failed if another node or other hardware failed while the object was open for write.

An NFS write operation is not considered to have failed if the TCP connection broke. This is because HCP doesn’t see the failure. In this case, lazy close applies, and the object is

considered complete.

Objects left by failed NFS write operations: